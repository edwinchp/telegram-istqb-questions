[
  {
    "question": "Which one of the following answers describes a test condition?",
    "options": [
      "A distinguishing characteristic of a component or system",
      "A testable aspect of a component or system identified as a basis for testing",
      "The degree to which a software product provides functions which meet needs when the software is used",
      "Test cases designed to execute combinations of conditions and actions resulting from them"
    ],
    "answer": "b",
    "explanation": ""
  },
  {
    "question": "Which of the following statements is a valid objective for testing?",
    "options": [
      "Test should start as late as possible so that development had enough time to create a good product",
      "To validate whether the test object works as expected by the users and other stakeholders",
      "To prove that all possible defects are identified",
      "To prove that any remaining defects will not cause any failures"
    ],
    "answer": "b",
    "explanation": ""
  },
  {
    "question": "Which of the following statements correctly describes the difference between testing and debugging?",
    "options": [
      "Testing identifies the source of defects; debugging analyzes the defects and proposes prevention",
      "Dynamic testing shows failures caused by defects; debugging eliminates defects",
      "Testing removes faults; but debugging removes defects that cause the faults",
      "Dynamic testing prevents the causes of failures; debugging removes the failures"
    ],
    "answer": "b",
    "explanation": ""
  },
  {
    "question": "Which one of the statements below describes the most common situation for a failure discovered during testing or in production?",
    "options": [
      "The product crashed when the user selected an option in a dialog box",
      "The wrong version of a compiled source code file was included in the build",
      "The computation algorithm used the wrong input variables",
      "The developer misinterpreted the requirement for the algorithm"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "Mr. Test, a mobile software tester with 5 years of experience, achieved exceptional results in a short time. However, he didn't modify or create new automated test cases for months, leading to fewer defects being detected during testing. What testing principle did Mr. Test overlook?",
    "options": [
      "Testing depends on the environment",
      "Exhaustive testing is not possible",
      "Repeating of same tests will not find new defects",
      "Defects cluster together"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "In what way can testing be part of Quality Assurance?",
    "options": [
      "It ensures that requirements are detailed enough",
      "Testing reduces the risk of poor software quality",
      "It ensures that standards in the organization are followed",
      "It measures the quality of software in terms of number of executed test cases"
    ],
    "answer": "b",
    "explanation": ""
  },
  {
    "question": "Which of the following activities is part of the main activity 'test analysis' in the test process?",
    "options": [
      "Identifying any required infrastructure and tools",
      "Creating test suites from test scripts",
      "Analyzing lessons learned for process improvement",
      "Evaluating the test basis for testability"
    ],
    "answer": "d",
    "explanation": ""
  },
  {
    "question": "How can white-box testing be applied during user acceptance testing?",
    "options": [
      "To check if large volumes of data can be transferred between integrated systems",
      "To check if all code statements and code decision paths have been executed",
      "To check if all work process flows have been covered",
      "To cover all web page navigations"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "Which one of the following is the BEST definition of an incremental development model?",
    "options": [
      "Defining requirements, designing and testing are done in phases where in each phase a piece is added",
      "A phase in the development process should begin when the previous phase is complete",
      "Testing is viewed as a separate phase which takes place after development has been completed",
      "Testing is added to development as an increment"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "Which of the following should NOT be a trigger for maintenance testing?",
    "options": [
      "Decision to test the maintainability of the software",
      "Decision to test the system after migration to a new operating platform",
      "Decision to test if archived data is possible to be retrieved",
      "Decision to test after 'hot fixes'"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "Which of the following options are roles in a formal review?",
    "options": [
      "Author, Moderator, Review leader, Manager, Scribe",
      "Author, Moderator, Manager, Reviewer, Developer",
      "Author, Manager, Review leader, Reviewer, Designer",
      "Author, Manager, Review leader, Reviewer, Designer",
      "Author, Moderator, Review leader, Reviewer, Scribe"
    ],
    "answer": "d",
    "explanation": ""
  },
  {
    "question": "Which activities are carried out within the planning of a formal review?",
    "options": [
      "Collection of metrics for the evaluation of the effectiveness of the review",
      "Answer any questions the participants may have",
      "Definition and Verification of fulfillment of entry criteria for the review",
      "Evaluation of the review findings against the exit criteria"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "Which of the review types below is the BEST option to choose when the review must follow a formal process based on rules and checklists?",
    "options": [
      "Informal Review",
      "Technical Review",
      "Inspection",
      "Walkthrough"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "Which of the following statements about static testing are MOST true?",
    "options": [
      "Static testing is a cheap way to detect and remove defects",
      "Static testing makes dynamic testing less challenging",
      "Static testing makes it possible to find run-time problems early in the lifecycle",
      "Static testing better for safety-critical systems; dynamic testing finds defects better."
    ],
    "answer": "b",
    "explanation": ""
  },
  {
    "question": "What is checklist-based testing?",
    "options": [
      "A test technique based on tester's knowledge of past faults or general knowledge of failures",
      "A test technique based on an analysis of the specification of a component or system",
      "Experience-based technique where tester uses a list of items or criteria to verify product",
      "Testers dynamically design and execute tests based on knowledge and exploration of test item"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "The statement on decision coverage suggests that when there is only one 'if' statement with no loops or CASE statements, and its execution is not nested, running any single test case results in 50% decision coverage.\n\nWhat is the correct statement regarding this?",
    "options": [
      "It's true. Any single test case provides 100% statement coverage and therefore 50% decision coverage",
      "It's true. Any single test case would cause the outcome of the “if” statement to be true or false",
      "It's false. A single test case can only guarantee 25% decision coverage in this case",
      "It's false. The statement is too broad. It may be correct or not, depending on the tested software"
    ],
    "answer": "b",
    "explanation": ""
  },
  {
    "question": "Which one of the following is the description of statement coverage?",
    "options": [
      "It is a metric, which is the percentage of test cases that have been executed",
      "It is a metric, which is the percentage of statements in the source code that have been executed",
      "It is a metric that counts the number of executed statements in the source code by passed test cases",
      "It is a metric, that gives a true/false confirmation if all statements are covered or not"
    ],
    "answer": "b",
    "explanation": ""
  },
  {
    "question": "Which statement about the relationship between statement coverage and decision coverage is true?",
    "options": [
      "100% decision coverage also guarantees 100% statement coverage",
      "100% statement coverage also guarantees 100% decision coverage",
      "50% decision coverage also guarantees 50% statement coverage",
      "Decision coverage can never reach 100%"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "For which of the following situations is exploratory testing suitable?",
    "options": [
      "When time pressure requires speeding up the execution of tests already specified",
      "When the system is developed incrementally, and no test charter is available",
      "When testers are available who have enough knowledge of similar applications and technologies",
      "When there is prior knowledge of the system and it should undergo extensive testing"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "Which one of the following is NOT included in a test summary report?",
    "options": [
      "Defining pass/fail criteria and objectives of testing",
      "Deviations from the test approach",
      "Measurements of actual progress against exit criteria",
      "Evaluation of the quality of the test object"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "Which one of the following is the characteristic of a metrics-based approach for test estimation?",
    "options": [
      "Budget which was used by a previous similar test project",
      "Overall experience collected in interviews with test managers",
      "Estimation of effort for test automation agreed in the test team",
      "Average of calculations collected from business experts"
    ],
    "answer": "a",
    "explanation": "There are a number of estimation techniques used to determine the effort required for adequate testing.\nTwo of the most commonly used techniques are: metrics-based, expert-based."
  },
  {
    "question": "Which one of the following is MOST likely to be a benefit of test execution tools?",
    "options": [
      "It is easy to create regression tests",
      "It is easy to maintain version control of test assets",
      "It is easy to design tests for security testing",
      "It is easy to run regression tests"
    ],
    "answer": "d",
    "explanation": ""
  },
  {
    "question": "Which one of the following test tools is mostly suitable for developers rather than testers?",
    "options": [
      "Requirement management tools",
      "Configuration management tools",
      "Static analysis tools",
      "Performance testing tools"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "White-box testing is a good candidate to apply unit testing.",
    "options": [
      "False",
      "True"
    ],
    "answer": "b",
    "explanation": "In a White-box testing you have access to the internal code and structure. Knowing this, you can apply unit testing."
  },
  {
    "question": "It can show failures that are caused by defects in the software.",
    "options": [
      "Testing",
      "Root cause",
      "Debugging",
      "Static testing"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "Development activity that find, analyzes and fixes defects.",
    "options": [
      "Testing",
      "Root cause",
      "Debugging",
      "Static testing"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "Includes all activities that direct and control an organization regarding quality.",
    "options": [
      "Quality Control",
      "Quality Management",
      "Debugging",
      "Static testing"
    ],
    "answer": "b",
    "explanation": "Quality management ties together the concept of Quality Assurance and Testing."
  },
  {
    "question": "It focuses on the adherence of the proper processes in order to provide confidence that level of quality will be achieved.",
    "options": [
      "Quality Control",
      "Quality Management",
      "Quality Assurance",
      "Static testing"
    ],
    "answer": "c",
    "explanation": "Quality Assurance focuses on the proper execution. It also belongs to larger concept called Quality Management."
  },
  {
    "question": "Involves many activities including test activities, that support the achievement of right levels of quality.",
    "options": [
      "Quality Control",
      "Quality Management",
      "Quality Assurance",
      "Static testing"
    ],
    "answer": "a",
    "explanation": "Quality Control belongs to larger concept called Quality Management."
  },
  {
    "question": "A person makes _____, which causes _____ in the software code, and when it is executed it causes _____ in the software.",
    "options": [
      "an error / a defect / a failure",
      "an error / a failure / a defect",
      "a defect / a defect / an error",
      "a failure / a defect / a failure"
    ],
    "answer": "a",
    "explanation": "Example: A programming error can lead to a defect in the code. If a defect is executed this may cause a failure in the application."
  },
  {
    "question": "Which one of the 7 principles represents this scenario:\n\nDuring testing, a software application is found to crash when a certain input is entered. This defect would have gone unnoticed if not for testing.",
    "options": [
      "Testing shows the presence of defects, not their absence",
      "Exhaustive testing is impossible",
      "Early testing saves time and money",
      "Defects cluster together",
      "Tests wear out",
      "Testing is context dependent",
      "Absence-of-defects fallacy"
    ],
    "answer": "a",
    "explanation": "Testing reduces the probability of undiscovered defects remaining in the software but, even if no defects are found, testing is not a proof of correctness."
  },
  {
    "question": "Which one of the 7 principles represents this scenario:\n\nAn e-commerce website with millions of products cannot be tested for every possible combination of inputs, so testers focus on the most important and high-risk areas, such as the checkout process.",
    "options": [
      "Testing shows the presence of defects, not their absence",
      "Exhaustive testing is impossible",
      "Early testing saves time and money",
      "Defects cluster together",
      "Tests wear out",
      "Testing is context dependent",
      "Absence-of-defects fallacy"
    ],
    "answer": "b",
    "explanation": "Rather than attempting to test exhaustively, risk analysis, test techniques, and priorities should be used to focus test efforts."
  },
  {
    "question": "Which one of the 7 principles represents this scenario:\n\nA defect is found in the requirements phase of a project, allowing the development team to correct it early, which is much cheaper and easier than fixing it later in the development process.",
    "options": [
      "Testing shows the presence of defects, not their absence",
      "Exhaustive testing is impossible",
      "Early testing saves time and money",
      "Defects cluster together",
      "Tests wear out",
      "Testing is context dependent",
      "Absence-of-defects fallacy"
    ],
    "answer": "c",
    "explanation": "To find defects early, both static and dynamic test activities should be started as early as possible in the software development lifecycle."
  },
  {
    "question": "Which one of the 7 principles represents this scenario:\n\nIn a medical software application, most defects are found in the module that handles patient data, prompting testers to focus their efforts on improving the quality of that module.",
    "options": [
      "Testing shows the presence of defects, not their absence",
      "Exhaustive testing is impossible",
      "Early testing saves time and money",
      "Defects cluster together",
      "Tests wear out",
      "Testing is context dependent",
      "Absence-of-defects fallacy"
    ],
    "answer": "d",
    "explanation": "A small number of modules usually contains most of the defects discovered during pre-release testing, or is responsible for most of the operational failures."
  },
  {
    "question": "Which one of the 7 principles represents this scenario:\n\nTesters find that the same test cases are not finding any new defects, so they review and update the test cases to include new scenarios and inputs to keep them effective.",
    "options": [
      "Testing shows the presence of defects, not their absence",
      "Exhaustive testing is impossible",
      "Early testing saves time and money",
      "Defects cluster together",
      "Tests wear out",
      "Testing is context dependent",
      "Absence-of-defects fallacy"
    ],
    "answer": "e",
    "explanation": "To detect new defects, existing tests and test data may need changing, and new tests may need to be written."
  },
  {
    "question": "Which one of the 7 principles represents this scenario:\n\nThe testing approach for a mobile game would be different from that of a safety-critical medical device. The former would require more exploratory testing, while the latter would require more rigorous testing and documentation.",
    "options": [
      "Testing shows the presence of defects, not their absence",
      "Exhaustive testing is impossible",
      "Early testing saves time and money",
      "Defects cluster together",
      "Tests wear out",
      "Testing is context dependent",
      "Absence-of-defects fallacy"
    ],
    "answer": "f",
    "explanation": "Example: Industrial software is tested differently from an e-commerce mobile app. Also testing in Agile is done differently than testing in sequential software development."
  },
  {
    "question": "Which one of the 7 principles represents this scenario:\n\nAn application has gone through testing and no defects have been found. However, when users use the application, they find new defects that were not found during testing, highlighting the importance of continuous testing and monitoring.",
    "options": [
      "Testing shows the presence of defects, not their absence",
      "Exhaustive testing is impossible",
      "Early testing saves time and money",
      "Defects cluster together",
      "Tests wear out",
      "Testing is context dependent",
      "Absence-of-defects fallacy"
    ],
    "answer": "g",
    "explanation": "Example: testing all requirements and fixing all defects found could still produce a system that is difficult to use, that does not fulfill the users’ needs and expectations."
  },
  {
    "messages": [
      "Order correctly these Test Process activities:\n\nA)Test analysis\nB)Test planning\nC)Test design\nD)Test monitoring and control\nE)Test execution\nF)Test implementation\nG)Test completion"
    ],
    "question": "Select your answer",
    "options": [
      "B, D, A, C, F, E, G",
      "B, D, A, C, E, F, G",
      "A, B, C, E, D, F, G",
      "A, B, C, D, E, F, G",
      "B, D, A, E, C, F, G"
    ],
    "answer": "a",
    "explanation": "Each constituent activity consists of multiple individual tasks, which would vary from one project or release to another."
  },
  {
    "question": "Involves activities that define the objectives of testing and the approach for meeting test objectives within constraints imposed by the context (e.g., specifying suitable test techniques and tasks, and formulating a test schedule for meeting a deadline).",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "Involves the on-going comparison of actual progress against planned progress using any test monitoring metrics defined in the test plan.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test monitoring",
      "Test control",
      "Test execution",
      "Test completion"
    ],
    "answer": "e",
    "explanation": ""
  },
  {
    "question": "Involves taking actions necessary to meet the objectives of the test plan (which may be updated over time).",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test monitoring",
      "Test control",
      "Test execution",
      "Test completion"
    ],
    "answer": "f",
    "explanation": ""
  },
  {
    "question": "It is supported by the evaluation of exit criteria, which are referred to as the definition of done in some software development lifecycle models.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "b",
    "explanation": ""
  },
  {
    "question": "During this test process, the test basis is analyzed to identify testable features and define associated test conditions. In other words, it determines “what to test” in terms of measurable coverage criteria.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "During this test process you perform the following tasks:\n\nAnalyze requirement specifications, Design and implementation, Risk analysis, Evaluate test items to identify defects.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "In which test process the application of black-box, white-box and experienced-based test techniques can be useful to reduce the likelihood of omitting important test conditions and to define accurate test conditions?",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "During this test process, the test conditions are elaborated into high-level test cases, sets of high-level test cases, and other testware. This test process answers the question “how to test?”",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "d",
    "explanation": "Test design may also result in the identification of similar types of defects in the test basis."
  },
  {
    "question": "This process includes the following major activities: Capturing bi-directional traceability between the test basis, test conditions, and test cases.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "d",
    "explanation": "Test design may also result in the identification of similar types of defects in the test basis."
  },
  {
    "question": "This test process includes the following major activities: Designing and prioritizing test cases and sets of test cases",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "d",
    "explanation": "Test design may also result in the identification of similar types of defects in the test basis."
  },
  {
    "question": "This test process includes the following major activities: Identifying necessary test data to support test conditions and test cases.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "d",
    "explanation": "Test design may also result in the identification of similar types of defects in the test basis."
  },
  {
    "question": "This test process includes the following major activities:\n\nDesign or plan the test environment and identifying any required infrastructure and tools.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "d",
    "explanation": "Test design may also result in the identification of similar types of defects in the test basis."
  },
  {
    "question": "During this test process, the testware necessary for test execution is created and/or completed, including sequencing the test cases into test procedures.\nIt answers the question “do we now have everything in place to run the tests?”",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "e",
    "explanation": ""
  },
  {
    "question": "This test process includes the following major activities:\n\nDeveloping and prioritizing test procedures, and, potentially, creating automated test scripts. Creating test suites from the test procedures and (if any) automated test scripts.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "e",
    "explanation": ""
  },
  {
    "question": "This test process includes the following major activities:\n\nArranging the test suites within a test execution schedule in a way that results in efficient test execution. Preparing test data and ensuring it is properly loaded in the test environment.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "e",
    "explanation": ""
  },
  {
    "question": "This test process includes the following major activities:\n\nBuild the test environment (including, potentially test harnesses, service virtualization simulators and other infrastructure items) and verifying that everything needed has been set up correctly.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "e",
    "explanation": ""
  },
  {
    "question": "This test process includes the following major activities:\n\nRecording the IDs and versions of the test item(s) or test object, test tool(s), and testware. Test either manually or by using test execution tools. Comparing actual results with expected results.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "f",
    "explanation": ""
  },
  {
    "question": "This test process includes the following major activities:\n\nReporting defects based on the failures observed. Logging the outcome of tests (e.g., pass, fail, blocked).",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "f",
    "explanation": ""
  },
  {
    "question": "This test process includes the following major activities:\n\nCreating a test summary report to be communicated to stakeholders. Finalizing and archiving the test environment, the test data, the test infrastructure, and other testware for later reuse.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "g",
    "explanation": "Test completion activities collect data from completed test activities to consolidate experience, testware, and any other relevant information."
  },
  {
    "question": "This test process includes the following major activities:\n\nAnalyzing lessons learned from the concluded test activities to determine changes needed for future iterations, releases, and projects. Using the information gathered to improve test process maturity.",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design",
      "Test implementation",
      "Test execution",
      "Test completion"
    ],
    "answer": "g",
    "explanation": "Test completion activities collect data from completed test activities to consolidate experience, testware, and any other relevant information."
  },
  {
    "question": "It includes information about the test basis, to which the other test work products will be related via traceability information, as well as exit criteria (or definition of done) which will be used during test monitoring and control.",
    "options": [
      "Test planning work products",
      "Test monitoring and control work products",
      "Test analysis work products",
      "Test design work products",
      "Test implementation work products",
      "Test execution work products",
      "Test completion work products"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "It includes various types of test reports, including test progress reports produced on an ongoing and/or a regular basis, and test summary reports produced at various completion milestones.",
    "options": [
      "Test planning work products",
      "Test monitoring and control work products",
      "Test analysis work products",
      "Test design work products",
      "Test implementation work products",
      "Test execution work products",
      "Test completion work products"
    ],
    "answer": "b",
    "explanation": "All test reports should provide audience-relevant details about the test progress as of the date of the report, including summarizing the test execution results once those become available."
  },
  {
    "question": "It includes defined and prioritized test conditions, each of which is ideally bidirectionally traceable to the specific element(s) of the test basis it covers.",
    "options": [
      "Test planning work products",
      "Test monitoring and control work products",
      "Test analysis work products",
      "Test design work products",
      "Test implementation work products",
      "Test execution work products",
      "Test completion work products"
    ],
    "answer": "c",
    "explanation": "Test analysis may also result in the discovery and reporting of defects in the test basis."
  },
  {
    "question": "It results in test cases and sets of test cases to exercise the test conditions defined in test analysis.",
    "options": [
      "Test planning work products",
      "Test monitoring and control work products",
      "Test analysis work products",
      "Test design work products",
      "Test implementation work products",
      "Test execution work products",
      "Test completion work products"
    ],
    "answer": "d",
    "explanation": "It is often a good practice to design high-level test cases, without concrete values for input data and expected results."
  },
  {
    "question": "Includes: Test procedures and the sequencing of those test procedures. Test suites. A test execution schedule.",
    "options": [
      "Test planning work products",
      "Test monitoring and control work products",
      "Test analysis work products",
      "Test design work products",
      "Test implementation work products",
      "Test execution work products",
      "Test completion work products"
    ],
    "answer": "e",
    "explanation": ""
  },
  {
    "question": "Includes: Documentation of the status of individual test cases or test procedures (e.g., ready to run, pass, fail, blocked, deliberately skipped, etc.). Defect reports. Documentation about which test item(s), test object(s), test tools, and testware were involved in the testing.",
    "options": [
      "Test planning work products",
      "Test monitoring and control work products",
      "Test analysis work products",
      "Test design work products",
      "Test implementation work products",
      "Test execution work products",
      "Test completion work products"
    ],
    "answer": "f",
    "explanation": ""
  },
  {
    "question": "It includes test summary reports, action items for improvement of subsequent projects or iterations, change requests or product backlog items, and finalized testware.",
    "options": [
      "Test planning work products",
      "Test monitoring and control work products",
      "Test analysis work products",
      "Test design work products",
      "Test implementation work products",
      "Test execution work products",
      "Test completion work products"
    ],
    "answer": "g",
    "explanation": ""
  },
  {
    "question": "On which test level these defects are typically found?\n\nIncorrect functionality (e.g., not as described in design specifications). Data flow problems. Incorrect code and logic.",
    "options": [
      "Component testing",
      "Integration testing",
      "System testing",
      "Acceptance testing"
    ],
    "answer": "a",
    "explanation": "Component testing (also known as unit or module testing) focuses on components that are separately testable."
  },
  {
    "question": "On which test level these defects are typically found?\n\nFailures in communication between components. Unhandled or improperly handled communication failures between components. Incorrect assumptions about the meaning, units, or boundaries of the data being passed between components.",
    "options": [
      "Component testing",
      "Integration testing",
      "System testing",
      "Acceptance testing"
    ],
    "answer": "b",
    "explanation": "Integration testing focuses on interactions between components or systems."
  },
  {
    "question": "On which test level these defects are typically found?\n\nFailure to properly and completely carry out end-to-end functional tasks. Failure of the product to work properly in the environment(s). Failure to work as described in user manuals.",
    "options": [
      "Component testing",
      "Integration testing",
      "System testing",
      "Acceptance testing"
    ],
    "answer": "c",
    "explanation": "System testing should focus on the overall, end-to-end behavior of the system as a whole, both functional and non-functional."
  },
  {
    "question": "On which test level these defects are typically found?\n\nSystem workflows do not meet business or user requirements. Business rules are not implemented correctly. System does not satisfy contractual or regulatory requirements.",
    "options": [
      "Component testing",
      "Integration testing",
      "System testing",
      "Acceptance testing"
    ],
    "answer": "d",
    "explanation": "Acceptance testing, like system testing, typically focuses on the behavior and capabilities of a whole system or product."
  },
  {
    "question": "_____ is often the responsibility of developers. ______ is generally the responsibility of testers. Ideally, when testers performing it should understand the system architecture.",
    "options": [
      "Component integration testing / System integration testing",
      "System integration testing / Component integration testing",
      "System integration testing / Integration testing",
      "Acceptance testing / Component integration testing"
    ],
    "answer": "a",
    "explanation": ""
  },
  {
    "question": "It focuses on the behavior and capabilities of a whole product, often considering the end-to-end tasks the product can perform and the non-functional behaviors it exhibits while performing those tasks.",
    "options": [
      "Component testing",
      "Integration testing",
      "System testing",
      "Acceptance testing"
    ],
    "answer": "c",
    "explanation": ""
  },
  {
    "question": "It typically focuses on the behavior and capabilities of a whole product. Validating that it is complete and will work as expected. And also establishing confidence in the quality. Defects may be found, but doing it is often not an objective.",
    "options": [
      "Component testing",
      "Integration testing",
      "System testing",
      "Acceptance testing"
    ],
    "answer": "d",
    "explanation": "Finding a significant number of defects during acceptance testing may in some cases be considered a major project risk."
  },
  {
    "question": "The main objective is building confidence that the users can use the system to meet their needs, fulfill requirements, and perform business processes with minimum difficulty, cost, and risk.",
    "options": [
      "User acceptance testing (UAT)",
      "Operational acceptance testing (OAT)",
      "Contractual and regulatory acceptance testing",
      "Alpha and beta testing"
    ],
    "answer": "a",
    "explanation": "It is typically focused on validating the fitness for use of the system by intended users in a real or simulated environment."
  },
  {
    "question": "Aspects focused on this acceptance testing:\n\nDisaster recovery. User management. Maintenance tasks. Testing of backup/restore. Load and migration tasks.",
    "options": [
      "User acceptance testing (UAT)",
      "Operational acceptance testing (OAT)",
      "Contractual and regulatory acceptance testing",
      "Alpha and beta testing"
    ],
    "answer": "b",
    "explanation": "The objective is building confidence that the system administrators can keep the system working properly even under difficult conditions."
  },
  {
    "question": "It is performed against an agreement of acceptance criteria for producing custom-developed software. Acceptance criteria should be defined when the parties agree to the commitment.",
    "options": [
      "User acceptance testing (UAT)",
      "Operational acceptance testing (OAT)",
      "Contractual and regulatory acceptance testing",
      "Alpha and beta testing"
    ],
    "answer": "c",
    "explanation": "Regulatory acceptance testing is often performed by users or by independent testers, sometimes with the results being witnessed or audited by regulatory agencies."
  },
  {
    "question": "It is used by developers of commercial off-the-shelf (COTS) software who want to get feedback from potential or existing users, customers, and/or operators before the software product is put on the market. ",
    "options": [
      "User acceptance testing (UAT)",
      "Operational acceptance testing (OAT)",
      "Contractual and regulatory acceptance testing",
      "Alpha and beta testing"
    ],
    "answer": "d",
    "explanation": ""
  },
  {
    "question": "It is performed at the developing organization’s site, not by the development team, but by potential or existing customers, and/or operators or an independent test team.",
    "options": [
      "User acceptance testing (UAT)",
      "Operational acceptance testing (OAT)",
      "Alpha and beta testing",
      "Alpha testing",
      "Beta testing"
    ],
    "answer": "d",
    "explanation": ""
  },
  {
    "question": "It is performed by potential or existing customers, and/or operators at their own locations.",
    "options": [
      "User acceptance testing (UAT)",
      "Operational acceptance testing (OAT)",
      "Alpha and beta testing",
      "Alpha testing",
      "Beta testing"
    ],
    "answer": "e",
    "explanation": ""
  },
  {
    "question": "It involves tests that evaluate functions that the system should perform. Work products could be business requirements specifications, epics, user stories, use cases, or functional specifications, or they may be undocumented.",
    "options": [
      "Functional testing",
      "Non-functional testing",
      "White-box testing",
      "Black-box testing",
      "Change-related testing"
    ],
    "answer": "a",
    "explanation": "The functions are “what” the system should do."
  },
  {
    "question": "It evaluates characteristics of systems and software such as usability, performance efficiency or security. Refer to ISO standard (ISO/IEC 25010) for a classification of software product quality characteristics.",
    "options": [
      "Functional testing",
      "Non-functional testing",
      "White-box testing",
      "Black-box testing",
      "Change-related testing"
    ],
    "answer": "b",
    "explanation": "Non-functional testing is the testing of “how well” the system behaves."
  },
  {
    "question": "It evaluates characteristics of systems and software such as usability, performance efficiency or security. It is the testing of “how well” the system behaves.",
    "options": [
      "Functional testing",
      "Non-functional testing",
      "White-box testing",
      "Black-box testing",
      "Shift-Left testing",
      "Change-related testing"
    ],
    "answer": "b",
    "explanation": "The late discovery of non-functional defects can be extremely dangerous to the success of a project."
  },
  {
    "question": "It is based on the system’s internal structure or implementation. Internal structure may include code, architecture, work flows, and/or data flows within the system.",
    "options": [
      "Functional testing",
      "Non-functional testing",
      "White-box testing",
      "Black-box testing",
      "Shift-Left testing",
      "Change-related testing"
    ],
    "answer": "c",
    "explanation": "It requires special skills or knowledge, such as the way the code is built and how data is stored."
  },
  {
    "question": "It is required when new features, modification to existing features, and code refactoring result in frequent alteration to the code.",
    "options": [
      "Functional testing",
      "Non-functional testing",
      "White-box testing",
      "Black-box testing",
      "Change-related testing"
    ],
    "answer": "e",
    "explanation": ""
  },
  {
    "messages": [
      "We need to calculate an employee bonus. It can't be negative, it could be zero and it is based on job duration:\nLess or equal to 2 years\nMore than 2 years but less than 5 years\nMore than 5 years but less than 10 years or more than 10 years\n\nWhat is the minimum scenarios required to cover all valid equivalence partitioning to calculate the bonus?"
    ],
    "question": "Select ONE option:",
    "options": [
      "3",
      "5",
      "2",
      "4"
    ],
    "answer": "d",
    "explanation": "You need 4 if you divide the range like this:\n0 1 2 - 3 4 - 5 6 7 8 9 10 - 11 12"
  },
  {
    "messages": [
      "A fitness application gives feedback based on the steps walked:\n0+ to 1000 steps\n1000+ to 2000 steps\n2000+ to 4000 steps\n4000+ to 6000 steps\n6000+ steps\n\nWhich input values would provide the highest equivalence partitioning coverage?"
    ],
    "question": "Select ONE option:",
    "options": [
      "0, 1000, 2000, 2973, 4000",
      "1000, 1001, 1999, 2000, 6000",
      "298, 2345, 3456, 4567, 5678",
      "598, 978, 2352, 5136, 6219"
    ],
    "answer": "d",
    "explanation": "It covers 4 of 5 partitions:\n598 (1), 978 (1), 2352 (3), 5136 (4), 6219 (5)"
  },
  {
    "messages": [
      "A temperature converter app provides the following output categories based on the input temperature:\nBelow freezing (<= 32°F)\nCold (33°F - 50°F)\nMild (51°F - 70°F)\nHot (> 70°F)\n\nWhich input values would provide the highest equivalence partitioning coverage?"
    ],
    "question": "Select ONE option:",
    "options": [
      "10, 30, 40, 80",
      "32, 33, 51, 70",
      "20, 35, 65, 80",
      "25, 45, 55, 75"
    ],
    "answer": "b",
    "explanation": "The input values 32, 33, 51, and 70 cover all four temperature categories:\nbelow freezing, cold, mild, and hot."
  },
  {
    "messages": [
      "A system categorizes customers into different tiers based on their purchase amount:\n0 - $100\n$101 - $500\n$501 - $1000\n$1001 - 5000\n5001 and above\n\nHow many scenarios are required to cover all valid equivalence partitions for determining the customer tier?"
    ],
    "question": "Select ONE option:",
    "options": [
      "3",
      "4",
      "5",
      "6"
    ],
    "answer": "c",
    "explanation": "You need 5 scenarios to cover all valid equivalence partitions:\n$5, $120, $705, $3876 and $5600."
  },
  {
    "question": "What is the purpose of bi-directional traceability in software testing?",
    "options": [
      "To establish a link between requirements and testing artifacts",
      "To identify defects in the software system",
      "To track the progress of the development team",
      "To create test cases for the software application"
    ],
    "answer": "a",
    "explanation": "Bi-directional traceability is used to establish and maintain a relationship between requirements and testing artifacts, such as test cases and defects."
  },
  {
    "question": "How does bi-directional traceability help in software testing?",
    "options": [
      "By ensuring complete test coverage of requirements",
      "By automatically generating test cases",
      "By prioritizing defects based on severity",
      "By tracking and verifying requirements throughout the testing process"
    ],
    "answer": "d",
    "explanation": "Bi-directional traceability helps in tracking and verifying requirements throughout the testing process, ensuring that they are adequately tested."
  },
  {
    "question": "In which scenarios is bi-directional traceability most useful?",
    "options": [
      "When there is no need to track requirements",
      "When testing activities are not documented",
      "When there are complex or changing requirements",
      "When test cases are not linked to requirements"
    ],
    "answer": "c",
    "explanation": "Bi-directional traceability is most useful in scenarios with complex or changing requirements, where tracking and verifying requirements become crucial for effective testing."
  },
  {
    "question": "Which of the following best describes ad hoc testing?",
    "options": [
      "Testing without a predefined test plan or script",
      "Testing that follows a rigorous and structured approach",
      "Testing that focuses solely on usability aspects",
      "Testing that is performed by end-users"
    ],
    "answer": "a",
    "explanation": "Ad hoc testing involves testing without a predefined test plan or script, relying on the tester's knowledge and experience."
  },
  {
    "question": "What are the potential drawbacks of relying solely on ad hoc testing?",
    "options": [
      "Lack of test coverage and traceability",
      "Inability to identify defects effectively",
      "Increased test execution time",
      "Difficulty in reproducing and documenting tests"
    ],
    "answer": "a",
    "explanation": "Relying solely on ad hoc testing can lead to drawbacks such as lack of test coverage and traceability, making it harder to ensure comprehensive testing."
  },
  {
    "question": "In which scenario would ad hoc testing be most beneficial?",
    "options": [
      "When strict adherence to a predefined test plan is required",
      "When the system under test has complex and constantly changing requirements",
      "When there is a need for automated test execution",
      "When the focus is primarily on performance testing"
    ],
    "answer": "b",
    "explanation": "Ad hoc testing is most beneficial when the system under test has complex and constantly changing requirements, as it allows for flexibility and adaptability in testing."
  },
  {
    "question": "What is the main difference between static testing and dynamic testing?",
    "options": [
      "Static testing focuses on code analysis, while dynamic testing involves executing the software",
      "Static testing is performed by end-users, while dynamic testing is performed by developers",
      "Static testing is used for small-scale projects, dynamic testing is used for large-scale projects",
      "Static testing requires test scripts, while dynamic testing does not"
    ],
    "answer": "a",
    "explanation": "The main difference is that static testing focuses on code analysis, such as reviews and inspections, while dynamic testing involves executing the software to observe its behavior."
  },
  {
    "question": "What are the benefits of static testing over dynamic testing?",
    "options": [
      "Early detection of defects and issues",
      "Higher test coverage and accuracy",
      "Identification of design flaws and improvements",
      "Real-time evaluation of performance and usability"
    ],
    "answer": "c",
    "explanation": "Static testing provides the benefits of identifying design flaws and improvements early in the development process, leading to higher software quality."
  },
  {
    "question": "Which testing technique is best suited for identifying defects in the early stages of the software development lifecycle?",
    "options": [
      "Unit testing",
      "Integration testing",
      "Dynamic testing",
      "Static testing"
    ],
    "answer": "d",
    "explanation": "Static testing, such as code reviews and inspections, is best suited for identifying defects in the early stages of the software development lifecycle, promoting early bug detection and prevention."
  },
  {
    "question": "What is the key advantage of static testing compared to dynamic testing?",
    "options": [
      "Early detection of defects before code execution",
      "Comprehensive evaluation of software performance",
      "Real-time validation of system functionality",
      "Validation of end-user requirements"
    ],
    "answer": "a",
    "explanation": "Static testing allows for the early identification of defects before the software is executed, helping to catch issues at an earlier stage."
  },
  {
    "question": "Which testing method is more effective for identifying design flaws and improving software quality?",
    "options": [
      "Dynamic testing",
      "Unit testing",
      "Integration testing",
      "Static testing"
    ],
    "answer": "d",
    "explanation": "Static testing is particularly useful for detecting design flaws and enhancing software quality by focusing on code analysis and reviews."
  },
  {
    "question": "What is a significant advantage of static testing in terms of test coverage?",
    "options": [
      "Higher accuracy in evaluating system behavior",
      "Thorough validation of end-user requirements",
      "Early detection of defects in code",
      "Improved coverage of code sections"
    ],
    "answer": "d",
    "explanation": "Static testing contributes to improved coverage by thoroughly examining code sections, which leads to more comprehensive testing."
  },
  {
    "question": "What type of defects are typically found during static testing?",
    "options": [
      "Requirement defects, design defects, security vulnerabilities",
      "Integration defects between system components",
      "Performance issues under heavy load and integration defects between system components",
      "User interface inconsistencies, logic errors within individual units of code"
    ],
    "answer": "a",
    "explanation": "Static testing can be used to improve the consistency and internal quality of work products, while dynamic testing typically focuses on externally visible behaviors."
  },
  {
    "question": "What type of defects are typically found during static testing?",
    "options": [
      "Wrong modularization, poor reusability of components, code that is difficult to analyze and modify",
      "Integration defects between system components",
      "Performance issues under heavy load and integration defects between system components",
      "User interface inconsistencies, logic errors within individual units of code"
    ],
    "answer": "a",
    "explanation": "Static testing can be used to improve the consistency and internal quality of work products, while dynamic testing typically focuses on externally visible behaviors."
  },
  {
    "question": "Which activities best describe the Review Process?",
    "options": [
      "Planning, Initiate review, Individual review, Issue communication and analysis, Fixing and reporting",
      "Planning, Analysis, Review, Plan execution, Fix and reporting, Review completion",
      "Initiate review, Initiate planning, Individual review, Fix and reporting, Review analysis",
      "Planning, Review implementation, Analysis, Plan execution, Fix and reporting, Review completion"
    ],
    "answer": "a",
    "explanation": "A review can focus on finding defects, gaining understanding, educating participants such as testers and new team members, or discussing and deciding by consensus."
  },
  {
    "question": "Black box technique that divides data based on the expectation that all the elements of a given divided area are to be processed in the same way by the test object.",
    "options": [
      "Equivalence Partitioning",
      "Boundary Value Analysis",
      "Decision Table Testing",
      "State Transition Testing"
    ],
    "answer": "a",
    "explanation": "The partitions may be continuous or discrete, ordered or unordered, finite or infinite. The partitions must not overlap and must be non-empty sets."
  },
  {
    "question": "Black box technique that is based on exercising the limits of equivalence partitions. Typical defects found are located where are misplaced to positions above or below their intended positions or are omitted altogether.",
    "options": [
      "Equivalence Partitioning",
      "Boundary Value Analysis",
      "Decision Table Testing",
      "State Transition Testing"
    ],
    "answer": "b",
    "explanation": "BVA can only be used for ordered partitions. The minimum and maximum values of a partition are its boundary values."
  },
  {
    "question": "Black box technique that is used for testing the implementation of system requirements that specify how different combinations of conditions result in different outcomes. It is an effective way of recording complex logic, such as business rules.",
    "options": [
      "Equivalence Partitioning",
      "Boundary Value Analysis",
      "Decision Table Testing",
      "State Transition Testing"
    ],
    "answer": "c",
    "explanation": "It provides a systematic approach to identify all the combinations of conditions, some of which might otherwise be overlooked."
  },
  {
    "question": "Black box technique that models the behavior of a system by showing its possible condition or situation and a valid alteration. Which is initiated by an event, which may be additionally qualified by a guard condition.",
    "options": [
      "Equivalence Partitioning",
      "Boundary Value Analysis",
      "Decision Table Testing",
      "State Transition Testing"
    ],
    "answer": "d",
    "explanation": "One test case may, and usually will, cover several transitions between states."
  },
  {
    "question": "Which of the following sentence is TRUE regarding State Transition Testing coverage?",
    "options": [
      "All states coverage is weaker than valid transitions; not all transitions need to be exercised.",
      "All states coverage equals valid transitions coverage; both cover all states and transitions.",
      "Valid transitions coverage is weaker than all states; not all transitions need to be exercised.",
      "Valid transitions coverage is weaker than all transitions; valid transitions have narrower scope."
    ],
    "answer": "a",
    "explanation": "Achieving full valid transitions coverage guarantees full all states coverage."
  },
  {
    "question": "It is a transfer of control between two nodes in the control flow graph, which shows the possible sequences in which source code statements are executed in the test object.",
    "options": [
      "Branch",
      "Branch testing",
      "White-box testing",
      "Statement testing"
    ],
    "answer": "a",
    "explanation": "Each transfer of control can be either unconditional (i.e., straight-line code) or conditional (i.e., a decision outcome)."
  },
  {
    "question": "Which of the following sentence is TRUE regarding Branch coverage?",
    "options": [
      "100% branch coverage also achieves 100% statement coverage (but not vice versa)",
      "100% statement coverage also achieves 100% branch coverage (but not vice versa)",
      "100% branch coverage also achieves 50% statement coverage",
      "100% statement coverage also achieves 50% branch coverage"
    ],
    "answer": "a",
    "explanation": "When 100% branch coverage is achieved, all branches in the code, unconditional and conditional, are exercised by test cases."
  },
  {
    "question": "Which of these statements best describes the testing quadrant Q1 (technology facing, support the team)?",
    "options": [
      "It contains component tests. Tests should be automated and included in the CI process.",
      "It contains functional tests, user story tests, user experience prototypes and API testing.",
      "It contains exploratory testing, usability testing, user acceptance testing.",
      "It contains smoke tests and non-functional tests (except usability tests)."
    ],
    "answer": "a",
    "explanation": "Testing quadrants group the test levels with the appropriate test types, activities, test techniques and work products in the Agile software development."
  },
  {
    "question": "Which of these statements best describes the testing quadrant Q2 (business facing, support the team)?",
    "options": [
      "It contains component tests. Tests should be automated and included in the CI process.",
      "It contains functional tests, user story tests, user experience prototypes and API testing.",
      "It contains exploratory testing, usability testing, user acceptance testing.",
      "It contains smoke tests and non-functional tests (except usability tests)."
    ],
    "answer": "b",
    "explanation": "Testing quadrants group the test levels with the appropriate test types, activities, test techniques and work products in the Agile software development."
  },
  {
    "question": "Which of these statements best describes the testing quadrant Q3 (business facing, critique the product)?",
    "options": [
      "It contains component tests. Tests should be automated and included in the CI process.",
      "It contains functional tests, user story tests, user experience prototypes and API testing.",
      "It contains exploratory testing, usability testing, user acceptance testing.",
      "It contains smoke tests and non-functional tests (except usability tests)."
    ],
    "answer": "c",
    "explanation": "Testing quadrants group the test levels with the appropriate test types, activities, test techniques and work products in the Agile software development."
  },
  {
    "question": "Which of these statements best describes the testing quadrant Q4 (technology facing, critique the product)?",
    "options": [
      "It contains component tests. Tests should be automated and included in the CI process.",
      "It contains functional tests, user story tests, user experience prototypes and API testing.",
      "It contains exploratory testing, usability testing, user acceptance testing.",
      "It contains smoke tests and non-functional tests (except usability tests)."
    ],
    "answer": "d",
    "explanation": "Testing quadrants group the test levels with the appropriate test types, activities, test techniques and work products in the Agile software development."
  },
  {
    "question": "Which of the following sentences is most TRUE about the Test Pyramid model?",
    "options": [
      "The higher layer, lower granularity. Bottom layer: small, isolated, fast tests.",
      "The higher layer, higher granularity. Bottom layer: large, isolated, slow tests.",
      "High-level tests are fast, check small functionality pieces.",
      "High-level tests are slower, cover large functionality pieces."
    ],
    "answer": "a",
    "explanation": "The pyramid layers represent groups of tests. The higher the layer, the lower the test granularity, test isolation and test execution time."
  },
  {
    "question": "In this test estimation technique, figures are collected from previous projects within the organization, which makes it possible to derive “standard” proportion for similar projects. This organization’s own projects are generally the best source to use in the estimation process.",
    "options": [
      "Estimation based on ratios",
      "Extrapolation",
      "Wideband Delphi",
      "Three-point estimation"
    ],
    "answer": "a",
    "explanation": "Test effort estimation involves predicting the amount of test-related work needed to meet the objectives of a test project."
  },
  {
    "question": "In this test estimation technique, measurements are made as early as possible in the current project to gather the data. Having enough observations, the effort required for the remaining work can be approximated by comparing and hypothesize this data.",
    "options": [
      "Estimation based on ratios",
      "Extrapolation",
      "Wideband Delphi",
      "Three-point estimation"
    ],
    "answer": "b",
    "explanation": "This method is very suitable in iterative SDLCs. For example, the team may extrapolate the test effort in the forthcoming iteration as the averaged effort from the last three iterations."
  },
  {
    "question": "In this test estimation technique, experts estimate effort individually. Deviations outside agreed boundaries trigger discussions. Experts revise their estimates based on feedback. The process continues until a consensus is reached. Experience-based estimations and collaboration are key.",
    "options": [
      "Estimation based on ratios",
      "Extrapolation",
      "Wideband Delphi",
      "Three-point estimation"
    ],
    "answer": "c",
    "explanation": "Planning Poker is a variant of Wideband Delphi, commonly used in Agile software development. In Planning Poker, estimates are usually made using cards with numbers that represent the effort size."
  },
  {
    "question": "In this test estimation technique, there are estimations made by the experts: the most optimistic estimation (a), the most likely estimation (m) and the most pessimistic estimation (b). The final estimate (E) is their weighted arithmetic mean.",
    "options": [
      "Estimation based on ratios",
      "Extrapolation",
      "Wideband Delphi",
      "Three-point estimation"
    ],
    "answer": "d",
    "explanation": "In the most popular version of this technique, the estimate is calculated as\nE = (a + 4*m + b) / 6"
  },
  {
    "question": "Which of the following is NOT associated with a product risk?",
    "options": [
      "Delays in work product deliveries occur in a software project due to miscommunication between teams.",
      "A software defect in an autonomous vehicle control system causes a critical failure.",
      "A software bug in a logistics management system causes incorrect shipping information.",
      "Users of a mobile banking app are dissatisfied with its slow performance and frequent crashes."
    ],
    "answer": "a",
    "explanation": "Product risks are related to the product quality characteristics."
  },
  {
    "question": "Which of the following is NOT associated with a project risk?",
    "options": [
      "A software defect in an autonomous vehicle control system causes a critical failure.",
      "Insufficient skills of the development team members lead to frequent code defects.",
      "A third-party software vendor fails to deliver a component on time, causing delays in the schedule.",
      "Additional features and requirements are continuously added without impact analysis."
    ],
    "answer": "a",
    "explanation": "Project risks are related to the management and control of the project."
  },
  {
    "question": "Which of the following is NOT a benefit of test automation?",
    "options": [
      "Detection of early security vulnerabilities and higher coverage assuming the absence of defects.",
      "More objective assessment (coverage) and providing measures complicated for humans to derive.",
      "Prevention of simple human errors through greater consistency and repeatability.",
      "Easier access to information about testing to support and test reporting (e.g., statistics, graphs)"
    ],
    "answer": "a",
    "explanation": "Automated tests may provide coverage but cannot guarantee the absence of defects."
  },
  {
    "question": "Which of the Software Development practices best describes the following:\n\nDirects the coding through test cases. Tests are written first, then the code is written to satisfy the test, and then the tests and code are refactored.",
    "options": [
      "Test-Driven Development (TDD)",
      "Acceptance Test-Driven Development (ATDD)",
      "Behavior-Driven Development (BDD)"
    ],
    "answer": "a",
    "explanation": "Example: Writing unit tests for a function that calculates the total price of items in an online shopping cart."
  },
  {
    "question": "Which of the Software Development practices best describes the following:\n\nDerives tests from the definition of done (conditions that a software product must satisfy) as part of the system design process. Tests are written before the part of the application is developed to satisfy the tests.",
    "options": [
      "Test-Driven Development (TDD)",
      "Acceptance Test-Driven Development (ATDD)",
      "Behavior-Driven Development (BDD)"
    ],
    "answer": "b",
    "explanation": "Example: Writing acceptance tests for a new feature of a web application to ensure it meets the specified requirements."
  },
  {
    "question": "Software Development practice that expresses the desired conduct of an application with test cases written in simple form of natural language, which is easy to understand by stakeholders (usually using the Given/When/Then format). Test cases are then translated into executable tests.",
    "options": [
      "Test-Driven Development (TDD)",
      "Acceptance Test-Driven Development (ATDD)",
      "Behavior-Driven Development (BDD)"
    ],
    "answer": "c",
    "explanation": "Example: Writing a BDD scenario in Given-When-Then format to describe the expected behavior of a login feature on a mobile app."
  },
  {
    "question": "Which of the statements is FALSE about DevOps and Testing?",
    "options": [
      "Decreases the focus on non-functional quality characteristics.",
      "Fast feedback on the code quality, and whether changes adversely affect existing code.",
      "Decreases manual labor by automating processes (CI/CD) that facilitate creating test environments.",
      "Minimizes the risk in regression due to the scale and range of automated regression tests."
    ],
    "answer": "a",
    "explanation": "Increases the view on non-functional quality characteristics (e.g., performance, reliability). DevOps promotes team autonomy, fast feedback and integrated toolchains."
  },
  {
    "question": "Which test approach best describes this scenario:\n\nStatic analysis tools are used to analyze the source code for potential issues (standards violations, code complexity, potential bugs). This analysis is often performed before dynamic testing to identify potential problems early.",
    "options": [
      "Shift-Left testing",
      "White-box testing",
      "Black-box testing",
      "Functional testing"
    ],
    "answer": "a",
    "explanation": "Testing enters the picture at the very end or to the extreme right of the SDLC. Shift Left Testing literally pushes testing to the “left,” i.e., to earlier stages in the SDLC."
  },
  {
    "question": "Which of the following statements describe a valid test objective?",
    "options": [
      "To prove that there are no unfixed defects in the system under test",
      "To prove that there will be no failures after the implementation of the system into production",
      "To reduce the risk level of the test object and to build confidence in the quality level",
      "To verify that there are no untested combinations of inputs"
    ],
    "answer": "c",
    "explanation": "Testing finds defects and failures which reduces the level of risk and at the same time gives more confidence in the quality level of the test object."
  },
  {
    "question": "Which of the following options shows an example of test activities that contribute to success?",
    "options": [
      "Testers involved during SDLC activities will help to detect defects in work products",
      "Testers try not to disturb the developers while coding, so that the developers write better code",
      "Testers collaborating with end users improve the quality of defect reports during system testing",
      "Certified testers will design much better test cases than non-certified testers"
    ],
    "answer": "a",
    "explanation": "It is important that testers are involved from the beginning of the software development lifecycle (SDLC). It will increase understanding of design decisions and will detect defects early."
  },
  {
    "question": "You are assigned as a tester to new team. You have noticed that no changes have been made to the existing regression test cases for several iterations and no new regression defects were identified. Your manager is happy, but you are not. Which testing principle explains your skepticism?",
    "options": [
      "Tests wear out",
      "Absence-of-errors fallacy",
      "Defects cluster together",
      "Exhaustive testing is impossible"
    ],
    "answer": "a",
    "explanation": "This principle means that if the same tests are repeated over and over again, eventually these tests no longer find any new defects. This is probably why the tests all passed in this release as well."
  },
  {
    "question": "You work in a team that develops a mobile application for food ordering. In the current iteration the team decided to implement the payment functionality.\n\nWhich of the following activities is a part of test analysis?",
    "options": [
      "Estimating that testing the integration with the payment service will take 8 person-days",
      "Decide the team should test if it is possible to properly share payment between many users",
      "Using boundary value analysis (BVA) for the test cases that check the correct payment amount",
      "Analyzing the discrepancy between the actual result and expected result after executing a test case"
    ],
    "answer": "b",
    "explanation": "This is an example of defining test conditions which is a part of test analysis."
  },
  {
    "messages": [
      "Which of the following factors (i-v) have SIGNIFICANT influence on the test process?\n\ni. The SDLC\nii. The number of defects detected in previous projects\niii. The identified product risks\niv. New regulatory requirements forcing\nv. The number of certified testers in the organization"
    ],
    "question": "Select ONE option:",
    "options": [
      "i, ii have significant influence; iii, iv, v have not",
      "i, iii, iv have significant influence; ii, v have not",
      "ii, iv, v have significant influence; i, iii have not",
      "iii, v have significant influence; i, ii, iv have not"
    ],
    "answer": "b",
    "explanation": "ii. is false. The number of defects detected in previous projects may have some influence, but this is not as significant as i, iii and iv"
  },
  {
    "question": "Which of the following tasks belong MAINLY to a testing role?",
    "options": [
      "Configure test environments",
      "Maintain the product backlog",
      "Design solutions to new requirements",
      "Create the test plan"
    ],
    "answer": "a",
    "explanation": "The product backlog is built and maintained by the product owner. Design solutions is done by the development team. Create test plan is a managerial role."
  },
  {
    "question": "Which of the following tasks belong MAINLY to a testing role?",
    "options": [
      "Create the test plan",
      "Maintain the product backlog",
      "Design solutions to new requirements",
      "Report on achieved coverage"
    ],
    "answer": "d",
    "explanation": "The product backlog is built and maintained by the product owner. Design solutions is done by the development team. Create test plan is a managerial role."
  },
  {
    "messages": [
      "Which of the following skills (i-v) are the MOST important skills of a tester?\n\ni. Having domain knowledge\nii. Creating a product vision\niii. Being a good team player\niv. Planning and organizing the work of the team\nv. Critical thinking"
    ],
    "question": "Select ONE option:",
    "options": [
      "ii and iv are important; i, iii and v are not",
      "i, iii and v are important; ii and iv are not",
      "i, ii and v are important; iii and iv are not",
      "iii and iv are important; i, ii and v are not"
    ],
    "answer": "b",
    "explanation": "ii. This is a task of the business analyst together with the business representative.\niv. Is a task of the test manager or, mostly in an Agile project, the whole team, and not just the tester."
  },
  {
    "question": "How is the whole team approach present in the interactions between testers and business representatives?",
    "options": [
      "Business representatives decide on test automation approaches",
      "Testers help business representatives to define test strategy",
      "Business representatives are not part of the whole team approach",
      "Testers help business representatives to create suitable acceptance tests"
    ],
    "answer": "d",
    "explanation": "Testers will work closely with business representatives to ensure that the desired quality levels are achieved. This includes supporting and collaborating with them."
  },
  {
    "question": "Consider the following rule: “for every SDLC activity there is a corresponding test activity”. In which SDLC models does this rule hold?",
    "options": [
      "Only in sequential SDLC models",
      "Only in iterative SDLC models",
      "Only in iterative and incremental SDLC models",
      "In sequential, incremental, and iterative SDLC models"
    ],
    "answer": "d",
    "explanation": "This rule holds for all SDLC models."
  },
  {
    "question": "Which of the following statements BEST describes the acceptance test-driven development (ATDD) approach?",
    "options": [
      "In ATDD, acceptance criteria are typically created based on the given/when/then format",
      "In ATDD, test cases are mainly created at component testing and are code-oriented",
      "In ATDD, tests are created based on acceptance criteria to drive the software development",
      "In ATDD, tests are based on the desired behavior of the software, and makes it easier to understand"
    ],
    "answer": "c",
    "explanation": "given/when/then is ofter used in BDD. In acceptance test-driven development (ATDD) tests are written from acceptance criteria as part of the design process."
  },
  {
    "question": "Which of the following is NOT an example of the shift left approach?",
    "options": [
      "Reviewing the user requirements before they are formally accepted by the stakeholders",
      "Writing a component test before the corresponding code is written",
      "Executing a performance efficiency test for a component during component testing",
      "Writing a test script before setting up the configuration management process"
    ],
    "answer": "d",
    "explanation": "Test scripts should be subject to configuration management, so it makes no sense to create the test scripts before this process is set up."
  },
  {
    "question": "Which of the arguments below would you use to convince your manager to organize retrospectives at the end of each release cycle?",
    "options": [
      "Retrospectives are popular and valued by clients for process improvement",
      "Organizing retrospectives saves costs by capturing end user feedback",
      "Identified process weaknesses form a to-do list for continuous improvement",
      "Retrospectives embrace values like courage and respect for ongoing growth"
    ],
    "answer": "c",
    "explanation": "Regularly conducted retrospectives, when appropriate follow up activities occur, are critical to continual improvement of development and testing."
  },
  {
    "messages": [
      "Which types of failures (1-4) fit which test levels (A-D) BEST?\n1. Failures in system behavior\n2. Failures in communication between components\n3. Failures in logic in a module\n4. Failures in not implemented business rules\nA. Component testing\nB. Component integration testing\nC. System testing\nD. Acceptance testing"
    ],
    "question": "Select your answer:",
    "options": [
      "1D, 2B, 3A, 4C",
      "1D, 2B, 3C, 4A",
      "1B, 2A, 3D, 4C",
      "1C, 2B, 3A, 4D"
    ],
    "answer": "a",
    "explanation": "Component communication is tested during component integration testing (2B). Failures in logic can be found during component testing (3A).\nBusiness rules are the test basis for system testing (4C)."
  },
  {
    "messages": [
      "You are testing a user story with three acceptance criteria: AC1, AC2 and AC3. AC1 is covered by test case TC1, AC2 by TC2, and AC3 by TC3. The test execution history had three test runs on three consecutive versions of the software as follows:"
    ],
    "photos": [
      "istqb1_14.png"
    ],
    "question": "Tests are repeated once you are informed that all defects found in the test run are corrected and a new version of the software is available.\n\nWhich of the above tests are executed as regression tests?",
    "options": [
      "Only 4, 7, 8, 9",
      "Only 5, 7",
      "Only 4, 6, 8, 9",
      "Only 5, 6"
    ],
    "answer": "b",
    "explanation": "TC2 passed in Execution 1 (i.e., test (2)), so test (5) is a regression test. TC1 passed in the Execution 2 (i.e., test (4)), so test (7) is also a regression test."
  },
  {
    "question": "Which of the following is NOT a benefit of static testing?",
    "options": [
      "Having less expensive defect management due to the ease of detecting defects later in the SDLC",
      "Fixing defects during static testing is less expensive than fixing defects during dynamic testing",
      "Finding coding defects that might not have been found by only performing dynamic testing",
      "Detecting gaps and inconsistencies in requirements"
    ],
    "answer": "a",
    "explanation": "Defect management is not less expensive. Finding and fixing defects later in SDLC is more costly."
  },
  {
    "question": "Which of the following is a benefit of early and frequent feedback?",
    "options": [
      "It improves the test process for future projects",
      "It forces customers to prioritize their requirements based on agreed risks",
      "It is the only way to measure the quality of changes",
      "It helps avoid requirements misunderstandings"
    ],
    "answer": "d",
    "explanation": "Feedback improves test process, but if only wants to improve future projects, the feedback does not need to come frequently. Early and frequent feedback communicate potential problems."
  },
  {
    "messages": [
      "The reviews being used in your organization have the following attributes:\n• There is the role of a scribe\n• The main purpose is to evaluate quality\n• The meeting is led by the author of the work product\n• There is individual preparation\n• A review report is produced"
    ],
    "question": "Which of the following review types is MOST likely being used?",
    "options": [
      "Informal review",
      "Walkthrough",
      "Technical review",
      "Inspection"
    ],
    "answer": "b",
    "explanation": "The purpose is to evaluate quality – the purpose of evaluating quality is one of the most important objectives of a walkthrough."
  },
  {
    "question": "Which of these statements is NOT a factor that contributes to successful reviews?",
    "options": [
      "Participants should dedicate adequate time for the review",
      "Splitting large work products into small parts to make the required effort less intense",
      "Participants should avoid boredom behaviors (exasperation, hostility to other participants)",
      "Failures found should be acknowledged, appreciated, and handled objectively"
    ],
    "answer": "d",
    "explanation": "During reviews one can find defects, not failures."
  },
  {
    "question": "Which of the following is a characteristic of experience-based test techniques?",
    "options": [
      "Test cases are created based on detailed design information",
      "Items tested within the interface code section are used to measure coverage",
      "The techniques heavily rely on the tester’s knowledge of the software and the business domain",
      "The test cases are used to identify deviations from the requirements"
    ],
    "answer": "c",
    "explanation": "This knowledge and experience include expected use of the software, its environment, likely defects, and the distribution of those defects is used to define tests."
  },
  {
    "messages": [
      "You are testing a simplified apartment search form which has only two search criteria:\n\n• floor (with three possible options: ground floor; first floor; second or higher floor)\n\n• garden type (with three possible options: no garden; small garden; large garden)",
      "Only apartments on the ground floor have gardens. The form has a built-in validation mechanism that will not allow you to use the search criteria which violate this rule.",
      "Each test has two input values: floor and garden type. You want to apply equivalence partitioning (EP) to cover each floor and each garden type in your tests."
    ],
    "question": "What is the minimal number of test cases to achieve 100% EP coverage?",
    "options": [
      "3",
      "4",
      "5",
      "6"
    ],
    "answer": "b",
    "explanation": "”Small garden” and “large garden” can go only with “ground floor”, so 2 test cases with “ground floor” which cover these 2 “garden type” partitions. 2 more test cases to cover “floor” and ”no garden”."
  },
  {
    "messages": [
      "You are testing a system that calculates the final course grade for a given student.\nThe final grade is assigned based on the final result, according to the following rules:\n• 0 – 50 points: failed\n• 51 – 60 points: fair\n• 61 – 70 points: satisfactory\n• 71 – 80 points: good\n• 81 – 90 points: very good\n• 91 – 100 points: excellent\nYou have prepared the following set of test cases:"
    ],
    "photos": [
      "istqb1_21.png"
    ],
    "question": "What is the 2-value Boundary Value Analysis (BVA) coverage for the final result that is achieved with the existing test cases?",
    "options": [
      "50%",
      "60%",
      "33.%",
      "100%"
    ],
    "answer": "a",
    "explanation": "There are 12 boundary values. The test cases cover six of them (TC1 – 91, TC2 – 50, TC3 – 81, TC4 – 60, TC5 – 70 and TC7 – 51). Therefore, the test cases cover 6/12 = 50%."
  },
  {
    "messages": [
      "Your favorite bicycle daily rental store has just introduced a new Customer Relationship Management system and asked you, one of their most loyal members, to test it.\nThe implemented features are as follows:\n• Anyone can rent a bicycle, but members receive a 20% discount\n• However, if the return deadline is missed, the discount is no longer available\n• After 15 rentals, members get a gift: a T-Shirt\nDecision table describing the implemented features looks as follows:"
    ],
    "photos": [
      "istqb1_22.png"
    ],
    "question": "Based ONLY on the feature description of the Customer Relationship Management system, which of the above rules describes an impossible situation?",
    "options": [
      "R4",
      "R2",
      "R6",
      "R8"
    ],
    "answer": "d",
    "explanation": "No discount as a non-member that has also missed a deadline, but only members can receive a gift T-Shirt. Hence, the action is not correct."
  },
  {
    "messages": [
      "You test a system whose lifecycle is modeled by the state transition diagram shown below. The system starts in the INIT state and ends its operation in the OFF state."
    ],
    "photos": [
      "istqb1_23.png"
    ],
    "question": "What is the MINIMAL number of test cases to achieve valid transitions coverage?",
    "options": [
      "4",
      "2",
      "7",
      "3"
    ],
    "answer": "d",
    "explanation": "“test” and “error” transitions cannot occur in one test case. Neither can both “done” transitions."
  },
  {
    "question": "Your test suite achieved 100% statement coverage. What is the consequence of this fact?",
    "options": [
      "Each instruction in the code that contains a defect has been executed at least once",
      "Any test suite with more test cases than your test suite will also achieve 100% statement coverage",
      "Each path in the code has been executed at least once",
      "Every combination of input values has been tested at least once"
    ],
    "answer": "a",
    "explanation": "Since 100% statement coverage is achieved, every statement, including the ones with defects, must have been executed and evaluated at least once."
  },
  {
    "question": "Which of the following is NOT true for white-box testing?",
    "options": [
      "During white-box testing the entire software implementation is considered",
      "White-box coverage metrics can help identify additional tests to increase code coverage",
      "White-box test techniques can be used in static testing",
      "White-box testing can help identify gaps in requirements implementation"
    ],
    "answer": "d",
    "explanation": "This is the weakness of the white-box test techniques. They're not able to identify the missing implementation. They are based on the test object structure, not on the requirements specification."
  },
  {
    "messages": [
      "Which of the following BEST describes the concept behind error guessing?\n\na) Error guessing involves using your knowledge and experience of defects found in the past and typical errors made by developers\nb) Error guessing involves using your personal experience of development and the errors you made as a developer\nc) Error guessing requires you to imagine that you are the user of the test object and to guess errors the user could make interacting with it\nd) Error guessing requires you to rapidly duplicate the development task to identify the sort of errors a developer might make"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "a",
    "explanation": "The basic concept behind error guessing is that the tester tries to guess what errors may have been made by the developer and what defects may be in the test object based on past experience."
  },
  {
    "messages": [
      "In your project there has been a delay in the release of a brand-new application and test execution started late, but you have very detailed domain knowledge and good analytical skills.\nThe full list of requirements has not yet been shared with the team, but management is asking for some test results to be presented."
    ],
    "question": "Which test technique fits BEST in this situation?",
    "options": [
      "Checklist-based testing",
      "Error guessing",
      "Exploratory testing",
      "Branch testing"
    ],
    "answer": "c",
    "explanation": "Exploratory testing is most useful when there are few known specifications and/or there is a pressing timeline for testing."
  },
  {
    "messages": [
      "Which of the following BEST describes the way acceptance criteria can be documented?\n\na) Performing retrospectives to determine the actual needs of the stakeholders regarding a given user story\nb) Using the given/when/then format to describe an example test condition related to a given user story\nc) Using verbal communication to reduce the risk of misunderstanding the acceptance criteria by others\nd) Documenting risks related to a given user story in a test plan to facilitate the risk-based testing of a given user story"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "b",
    "explanation": "This is the standard way to document acceptance criteria."
  },
  {
    "messages": [
      "Consider the following user story:\n\n\"_As an Editor\nI want to review content before it is published\nso that I can assure the grammar is correct\"_\n\nand its acceptance criteria:\n\n• The user can log in to the content management system with \"Editor\" role\n• The editor can view existing content pages\n• The editor can edit the page content\n• The editor can add markup comments\n• The editor can save changes\n• The editor can reassign to the \"content owner\" role to make updates"
    ],
    "question": "Which of the following is the BEST example of an ATDD test for this user story?",
    "options": [
      "test if the editor can save the document after deleting the page content",
      "test if the content owner can log in and make updates to the content",
      "test if the editor can schedule the edited content for publication",
      "test if the editor can reassign to another editor to make updates"
    ],
    "answer": "a",
    "explanation": "This test covers two acceptance criteria: one about editing the document and one about saving changes."
  },
  {
    "messages": [
      "How do testers add value to iteration and release planning?",
      "a) Testers determine the priority of the user stories to be developed\n\nb) Testers focus only on the functional aspects of the system to be tested\n\nc) Testers participate in the detailed risk identification and risk assessment of user stories\n\nd) Testers guarantee the release of high-quality software through early test design during the release planning"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "c",
    "explanation": "According to the syllabus, this is one of the ways testers add value to iteration and release planning"
  },
  {
    "question": "Which of the following options is the exit criteria for testing a system?",
    "options": [
      "Estimated defect density is reached",
      "Test environment readiness",
      "The ability to log in to the test object by the tester",
      "Requirements are translated into given/when/then format"
    ],
    "answer": "a",
    "explanation": "Estimated defect density is a measure of diligence; hence it belongs to the exit criteria."
  },
  {
    "question": "Which of the following options is the exit criteria for testing a system?",
    "options": [
      "Regression tests are automated",
      "The ability to log in to the test object by the tester",
      "Test environment readiness",
      "Requirements are translated into given/when/then format"
    ],
    "answer": "a",
    "explanation": "Automation of regression tests is a completion criterion; hence it belongs to the exit criteria."
  },
  {
    "messages": [
      "Your team uses the three-point estimation technique to estimate the test effort for a new high-risk feature.\n\nThe following estimates were made:\n• most optimistic estimation: 2 person-hours\n• most likely estimation: 11 person-hours\n• most pessimistic estimation: 14 person-hours\n\nWhat is the final estimate?"
    ],
    "question": "Select ONE option:",
    "options": [
      "9 person-hours",
      "14 person-hours",
      "11 person-hours",
      "10 person-hours"
    ],
    "answer": "d",
    "explanation": "In the three-point estimation technique E = (optimistic + 4*most likely + pessimistic)/6,\nE = (2+(4*11)+14)/6 = 10."
  },
  {
    "messages": [
      "You are testing a mobile application that allows users to find a nearby restaurant based on the type of food they want to eat.\n\nConsider the following list of test cases, priorities (i.e., a smaller number means a higher priority), and dependencies:"
    ],
    "photos": [
      "istqb1_33.png"
    ],
    "question": "Which of the following test cases should be executed as the third one?",
    "options": [
      "TC 003",
      "TC 005",
      "TC 002",
      "TC 001"
    ],
    "answer": "a",
    "explanation": "Test TC 001 must come first, followed by TC 002, to satisfy dependencies. Afterwards, TC 003 to satisfy priority and then TC 004, followed by TC 005."
  },
  {
    "messages": [
      "Consider the following test categories (1-4) and agile testing quadrants (A-D):"
    ],
    "photos": [
      "istqb1_34.png"
    ],
    "question": "How do the following test categories map onto the agile testing quadrants?",
    "options": [
      "1C, 2A, 3B, 4D",
      "1D, 2A, 3C, 4B",
      "1C, 2B, 3D, 4A",
      "1D, 2B, 3C, 4A"
    ],
    "answer": "a",
    "explanation": "Usability testing is in Q3. Component testing is in Q1. Functional testing is in Q2. Reliability testing is in Q4."
  },
  {
    "messages": [
      "During a risk analysis the following risk was identified and assessed:"
    ],
    "photos": [
      "istqb1_35.png"
    ],
    "question": "Select ONE option:",
    "options": [
      "Risk acceptance",
      "Contingency plan",
      "Risk mitigation",
      "Risk transfer"
    ],
    "answer": "c",
    "explanation": "The proposed actions are related to testing, which is a form of risk mitigation."
  },
  {
    "question": "Which work product can be used by an agile team to show the amount of work that has been completed and the amount of total work remaining for a given iteration?",
    "options": [
      "Acceptance criteria",
      "Defect report",
      "Test completion report",
      "Burndown char"
    ],
    "answer": "d",
    "explanation": "Burndown charts are a graphical representation of work left to do versus time remaining. They are updated daily, so they can continuously show the work progress."
  },
  {
    "question": "You need to update one of the automated test scripts to be in line with a new requirement. Which process indicates that you create a new version of the test script in the test repository?",
    "options": [
      "Traceability management",
      "Maintenance testing",
      "Configuration management",
      "Requirements engineering"
    ],
    "answer": "c",
    "explanation": "Maintenance testing is about testing changes; it is not related closely to versioning. To support testing, configuration management may involves the version control of all test items."
  },
  {
    "messages": [
      "You received the following defect report from the developers stating that the anomaly described in this test report is not reproducible."
    ],
    "photos": [
      "istqb1_38.png"
    ],
    "question": "What critical information is MISSING from this test report that would have been useful for the developers?",
    "options": [
      "Expected result and actual result",
      "References and defect status",
      "Test environment and test item",
      "Priority and severity"
    ],
    "answer": "c",
    "explanation": "We do not know in which test environment the anomaly was detected, and we also do not know which application (and its version) is affected."
  },
  {
    "question": "Which test activity does a data preparation tool support?",
    "options": [
      "Test monitoring and control",
      "Test analysis and design",
      "Test implementation and execution",
      "Test completion"
    ],
    "answer": "c",
    "explanation": "Test implementation includes creating or acquiring the testware necessary for test execution (e.g., test data)"
  },
  {
    "question": "Which item correctly identifies a potential risk of performing test automation?",
    "options": [
      "It may introduce unknown regressions in production",
      "Sufficient efforts to maintain testware may not be properly allocated",
      "Testing tools and associated testware may not be sufficiently relied upon",
      "It may reduce the time allocated for manual testing"
    ],
    "answer": "b",
    "explanation": " Wrong allocation or distribution of effort to maintain testware is a risk."
  },
  {
    "question": "You were given a task to analyze and fix causes of failures in a new system to be released.\nWhich activity are you performing?",
    "options": [
      "Debugging",
      "Software testing",
      "Requirement elicitation",
      "Defect management"
    ],
    "answer": "a",
    "explanation": "Debugging is the process of finding, analyzing, and removing the causes of failures in a component or system."
  },
  {
    "messages": [
      "In many software organizations the test department is called the Quality Assurance (QA) department. Is this sentence correct or not and why?"
    ],
    "photos": [
      "istqb1_A2.png"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "d",
    "explanation": "Testing and quality assurance are not the same. Testing is the process consisting of all SDLC activities. Quality assurance is focused on introducing and adhering to the quality-related processes."
  },
  {
    "messages": [
      "A phone ringing in a neighboring cubicle distracts a programmer causing him to improperly program the logic that checks the upper boundary of an input variable. Later, during system testing, a tester notices that this input field accepts invalid input values."
    ],
    "question": "Which of the following correctly describes an incorrectly coded upper bound?",
    "options": [
      "The root cause",
      "A failure",
      "An error",
      "A defect"
    ],
    "answer": "d",
    "explanation": "The error is the mistaken thinking that resulted in putting the defect in the code.\nThe problem in the code is a defect."
  },
  {
    "messages": [
      "Consider the following testware."
    ],
    "photos": [
      "istqb1_A4.png"
    ],
    "question": "Which test activity produces this testware as an output?",
    "options": [
      "Test planning",
      "Test monitoring and control",
      "Test analysis",
      "Test design"
    ],
    "answer": "d",
    "explanation": "The testware under consideration is a test charter.\nTest charters are the output from test design."
  },
  {
    "messages": [
      "Which of the following is the BEST example of how traceability supports testing?",
      "a) Performing the impact analysis of a change will give information about the completion of the tests\n\nb) Analyzing the traceability between test cases and test results will give information about the estimated level of residual risk\n\nc) Performing the impact analysis of a change will help selecting the right test cases for regression testing\n\nd) Analyzing the traceability between the test basis, the test objects and the test cases will help in selecting test data to achieve the assumed coverage of the test object"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "c",
    "explanation": "b) Traceability alone doesn't reveal the estimated residual risk if test cases aren't linked to risks.\nd) Selecting test data is primarily tied to test analysis, rather than traceability."
  },
  {
    "messages": [
      "Which of the following BEST explains a benefit of independence of testing?",
      "a) The use of an independent test team allows project management to assign responsibility for the quality of the final deliverable to the test team\n\nb) If a test team external to the organization can be afforded, then there are distinct benefits in terms of this external team not being so easily swayed by the delivery concerns of project management and the need to meet strict delivery deadlines\n\nc) An independent test team can work separately from the developers, need not be distracted with project requirement changes, and can restrict communication with the developers to\ndefect reporting through the defect management system\n\nd) When specifications contain ambiguities and inconsistencies, assumptions are made on their interpretation, and an independent tester can be useful in questioning those assumptions and the interpretation made by the developer"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "d",
    "explanation": "a) Quality should be the responsibility of everyone, not only for the test team\nb) External test teams missing delivery deadlines isn't beneficial\nc) Testing in complete isolation is a poor practice"
  },
  {
    "question": "You are working as a tester in the team that follows the V-model. The choice of software development lifecycle (SDLC) model impacts the timing of testing, which of the following statement is NOT true?",
    "options": [
      "Dynamic testing can be performed early in the SDLC",
      "Static testing can be performed early in the SDLC",
      "Test planning can be performed early in the SDLC",
      "Acceptance testing can be performed early in the SDLC"
    ],
    "answer": "a",
    "explanation": "Acceptance testing can be performed when there is a working product. In sequential SDLC models the working product is usually delivered late in the SDLC"
  },
  {
    "messages": [
      "Which of the following are advantages of DevOps?",
      "i. Faster product release and faster time to market\n\nii. Increases the need for repetitive manual testing\n\niii. Constant availability of executable software\n\niv. Reduction in the number of regression tests associated with code refactoring\n\nv. Setting up the test automation framework is inexpensive since everything is automated"
    ],
    "question": "Select ONE option:",
    "options": [
      "i, ii, iv are advantages",
      "iii, v are advantages",
      "i, iii are advantages",
      "ii, iv, v are advantages"
    ],
    "answer": "c",
    "explanation": "iv. Is false. More regression tests are needed.\nv. Is false. Not everything is automated and setting up a test automation framework is expensive."
  },
  {
    "messages": [
      "You work as a tester in a project on a mobile application for food ordering for one of your clients.\nThe client sent you a list of requirements. One of them, with high priority, says:\n\n\n___“The order must be processed in less than 10 seconds in 95% of the cases.”___\n\n\nYou created a set of test cases in which a number of random orders were made, the processing time measured, and the test results were checked against the requirements."
    ],
    "question": "What test type did you perform?",
    "options": [
      "Functional, because the test cases cover the user’s business requirement for the system",
      "Non-functional, because the measure the system’s performance",
      "Functional, because the test cases interact with the user interface",
      "Structural; we need to know the internal structure of the program to measure the order time"
    ],
    "answer": "b",
    "explanation": "They focus on \"how\" the system operates, specifically regarding speed of order processing, rather than \"what\" it accomplishes.\nAnd there is no need to know the internal structure for such activity."
  },
  {
    "question": "Your organization’s test strategy suggests that once a system is going to be retired, data migration shall be tested.\nAs part of what test type is this testing MOST likely to be performed?",
    "options": [
      "Maintenance testing",
      "Regression testing",
      "Component testing",
      "Integration testing"
    ],
    "answer": "a",
    "explanation": "When a system is retired, this can require testing of data migration, which is a form of maintenance testing."
  },
  {
    "messages": [
      "The following is a list of the work products produced in the SDLC.\n\ni. Business requirements\nii. Schedule\niii. Test budget\niv. Third-party executable code\nv. User stories and their acceptance criteria"
    ],
    "question": "Which of them can be reviewed?",
    "options": [
      "i and iv can be reviewed",
      "i, ii, iii and iv can be reviewed",
      "i, ii, iii, and v can be reviewed",
      "iii, iv, v can be reviewed"
    ],
    "answer": "c",
    "explanation": "Only third-party executable code cannot be reviewed."
  },
  {
    "messages": [
      "Decide which of the following statements (i-v) are true for static testing.\n\ni. Abnormal external behaviors are easier to identify with this testing\nii. Discrepancies from a coding standard are easier to find with this testing\niii. It identifies failures caused by defects when the software is run\niv. Its test objective is to identify defects as early as possible\nv. Missing coverage for critical security requirements is easier to find and fix"
    ],
    "question": "Select ONE option:",
    "options": [
      "i, iv, v are true for static testing",
      "i, iii, iv are true for static testing",
      "ii, iii are true for static testing",
      "ii, iv, v are true for static testing"
    ],
    "answer": "d",
    "explanation": "i. These behaviors are easily detectable while the software is running. Hence, dynamic testing shall be used to identify them.\niii. If the software is executed during the test, it is dynamic testing."
  },
  {
    "question": "Which of the following statements about formal reviews is TRUE?",
    "options": [
      "Some reviews do not require more than one role",
      "The review process has several activities",
      "Documentation for review isn't distributed beforehand except for specific review types",
      "Defects found during the review are not reported since they are not found by dynamic testing"
    ],
    "answer": "b",
    "explanation": "All review types involve multiple roles, even informal ones.\nDistributing documentation for review as early as possible is crucial.\nAny defects identified during the review should be reported."
  },
  {
    "question": "What task may management take on during a formal review?",
    "options": [
      "a) Taking overall responsibility for the review",
      "b) Deciding what is to be reviewed",
      "c) Ensuring the effective running of review meetings, and mediating, if necessary",
      "d) Recording review information such as review decisions"
    ],
    "answer": "b",
    "explanation": "a) This is the task of the review leader.\nc) This is the task of the moderator.\nd) This is the task of the scribe."
  },
  {
    "messages": [
      "A wine storage system uses a control device that measures the wine cell temperature T (measured in °C, rounded to the nearest degree) and alarms the user if it deviates from the optimal value of 12, according to the following rules:\n\n\n• if T = 12, the system says, “optimal temperature”\n• if T < 12, the system says, “temperature is too low!”\n• if T > 12, the system says, “temperature is too high!”\n\n\nYou want to use the 3-point boundary value analysis (BVA) to verify the behavior of the control device. A test input is a temperature in °C provided by the device."
    ],
    "question": "What is the MINIMAL set of test inputs that achieves 100% of the desired coverage?",
    "options": [
      "11, 12, 13",
      "10, 12, 14",
      "10, 11, 12, 13, 14",
      "10, 11, 13, 14"
    ],
    "answer": "c",
    "explanation": "Three equivalence partitions: {10, 11} {12} {13, 14}\nBoundary values: 11, 12, 13\nIn three-point boundary value analysis testing includes each boundary and its neighbors: 10, 11, 12, 13, 14"
  },
  {
    "messages": [
      "Which of the following statements about branch testing is CORRECT?\n\n\na) If a program includes only unconditional branches, then 100% branch coverage can be achieved without executing any test cases\n\nb) If the test cases exercise all unconditional branches in the code, then 100% branch coverage is achieved\n\nc) If 100% statement coverage is achieved, then 100% branch coverage is also achieved\n\nd) If 100% branch coverage is achieved, then all decision outcomes in each decision statement in the code are exercised"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "d",
    "explanation": "a) Is incorrect. Still one test case is needed since there is at least one (unconditional) branch to be covered\nc) Is wrong. 100% branch coverage implies 100% statement coverage, not otherwise."
  },
  {
    "messages": [
      "You are testing a mobile application that allows customers to access and manage their bank accounts. You are running a test suite that involves evaluating each screen, and each field on each screen, against a general list of user interface best practices derived from a popular book on the topic that maximizes attractiveness, ease-of-use, and accessibility for such applications. Which of the following options BEST categorizes the test technique you are using?"
    ],
    "question": "Select ONE option:",
    "options": [
      "Black-box",
      "Exploratory",
      "Checklist-based",
      "Error guessing"
    ],
    "answer": "c",
    "explanation": "The list of user interface best practices is the list of test conditions to be systematically checked."
  },
  {
    "messages": [
      "Which of the following BEST describe the collaborative approach to user story writing?\n\n\na) User stories are created by testers and developers and then accepted by business representatives\n\nb) User stories are created by business representatives, developers, and testers together\n\nc) User stories are created by business representatives and verified by developers and testers\n\nd) User stories are created in a way that they are independent, negotiable, valuable, estimable, small, and testable"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "b",
    "explanation": "Collaborative user story writing means that all stakeholders create the user stories collaboratively, to obtain the shared vision."
  },
  {
    "messages": [
      "Consider the following part of a test plan.\n\n___Testing will be performed using component testing and component integration testing.\nThe regulations require to demonstrate that 100% branch coverage is achieved for each component classified as critical.___\n\nWhich part of the test plan does this part belong to?"
    ],
    "question": "Select ONE option:",
    "options": [
      "Communication",
      "Risk register",
      "Context of testing",
      "Test approach"
    ],
    "answer": "d",
    "explanation": "The paragraph contains information on test levels and exit criteria, which are part of the test approach."
  },
  {
    "messages": [
      "Your team uses planning poker to estimate the test effort for a newly required feature. There is a rule in your team that if there is no time to reach full agreement and the variation in the results is small, applying rules like “accept the number with the most votes” can be applied.\n\nAfter two rounds, the consensus was not reached, so the third round was initiated. You can see the test estimation results in the table below."
    ],
    "photos": [
      "istqb1_A20.png"
    ],
    "question": "Which of the following is the BEST example of the next step?",
    "options": [
      "The product owner has to step in and make a final decision",
      "Accept 13 as the final test estimate as this has most of the votes",
      "No further action is needed. Consensus has been reached",
      "Remove the new feature from the current release because consensus has not been reached"
    ],
    "answer": "b",
    "explanation": "If test estimates are not the same, but the variation in the results is small, applying rules like “accept the number with the most votes” can be applied."
  },
  {
    "messages": [
      "Which of the following is NOT true regarding the test pyramid?\n\n\na) The test pyramid emphasizes having a larger number of tests at the lower test levels\n\nb) The closer to the top of the pyramid, the more formal your test automation should be\n\nc) Usually, component testing and component integration testing are automated using APIbased tools\n\nd) For system testing and acceptance testing, the automated tests are typically created using GUI-based tools"
    ],
    "question": "Select ONE option:",
    "options": [
      "a)",
      "b)",
      "c)",
      "d)"
    ],
    "answer": "a",
    "explanation": "a) Is wrong. The test pyramid emphasizes having a larger number of tests at the lower test levels.\nb) Is correct. It is not true that near the top of pyramid, test automation should be more formal."
  }
]